{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nationwide\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from math import log10, floor\n",
    "\n",
    "# Read the CSV into a pandas DataFrame, making sure to parse the first column as dates\n",
    "# Specify the correct date format if pandas does not recognize it automatically\n",
    "ww = pd.read_csv(\"US_Biobot_county_data_2024-04-29.csv\", skiprows=2, parse_dates=['Date'], usecols=[1, 2, 5, 6], \n",
    "                 names=['County_FIPS', 'Date', 'Concentration', 'State_Abbrev'],\n",
    "                 date_parser=lambda x: pd.to_datetime(x, format='%Y-%m-%d'))\n",
    "\n",
    "# Turn County FIPS to int\n",
    "ww['County_FIPS'] = ww['County_FIPS'].astype(int)\n",
    "\n",
    "# Clean non-numeric characters from the concentration column if necessary\n",
    "# For example, if there are commas in the numbers or there are strings like '<1'\n",
    "ww['Concentration'] = pd.to_numeric(ww['Concentration'].replace('[^0-9.]', '', regex=True), errors='coerce')\n",
    "\n",
    "\n",
    "# Read FIPS and population data\n",
    "fips_pop_data = pd.read_csv('Fips_pop_short.csv')\n",
    "\n",
    "# Prepare the population data\n",
    "fips_pop_data['CENSUS_2020_POP'] = fips_pop_data['CENSUS_2020_POP'].fillna('0').str.replace(',', '').astype(int)\n",
    "\n",
    "# Merge the wastewater data with the population data\n",
    "merged_data = pd.merge(ww, fips_pop_data, left_on='County_FIPS', right_on='FIPStxt', how='left')\n",
    "\n",
    "# Load the conversion factors CSV\n",
    "conversion_factors_df = pd.read_csv('ConversionFactors/conversion_factors_by_state.csv')\n",
    "\n",
    "# Create a dictionary mapping state abbreviations to conversion factors\n",
    "conversion_factor_mapping = pd.Series(conversion_factors_df['Conversion Factor'].values, index=conversion_factors_df.State).to_dict()\n",
    "\n",
    "def round_to_two_significant_digits(num):\n",
    "    if num == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        round_digits = -int(floor(log10(abs(num)))) + 1\n",
    "        return round(num, round_digits)\n",
    "\n",
    "# Dictionary mapping state names to abbreviations\n",
    "state_name_to_abbreviation = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'United States Virgin Islands': 'VI',\n",
    "    'Vermont': 'VT',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY'\n",
    "}\n",
    "\n",
    "rows_list = []\n",
    "states = merged_data['State_Abbrev'].unique()\n",
    "\n",
    "for state in states:\n",
    "    # Filter for current state\n",
    "    state_merged_data = merged_data[merged_data['State_Abbrev'] == state]\n",
    "\n",
    "    # Calculate the weighted average for the current state\n",
    "    state_weighted_avg_data = state_merged_data.groupby('Date').apply(lambda x: (x['Concentration'] * x['CENSUS_2020_POP']).sum() / x['CENSUS_2020_POP'].sum()).reset_index(name='weighted_avg_conc')\n",
    "    state_weighted_avg_data['Date'] = pd.to_datetime(state_weighted_avg_data['Date'])\n",
    "    state_weighted_avg_data = state_weighted_avg_data.sort_values('Date')\n",
    "\n",
    "    # Prepare the wastewater data for the analysis period\n",
    "    ww_state = state_weighted_avg_data.copy()\n",
    "    if ww_state['Date'].size > 20:\n",
    "        ww_state = ww_state.set_index('Date').resample('D').interpolate().reset_index()\n",
    "        ww_state = ww_state[['Date', 'weighted_avg_conc']]\n",
    "        ww_state['Date'] = pd.to_datetime(ww_state['Date'])\n",
    "    else:\n",
    "        # Use national average for comparison if there is not enough data\n",
    "        ww_state = ww_state.set_index('Date').resample('D').interpolate().reset_index()\n",
    "        ww_state = ww_state[['Date', 'weighted_avg_conc']]\n",
    "        ww_state['Date'] = pd.to_datetime(ww_state['Date'])\n",
    "\n",
    "        \n",
    "    # Apply the conversion factor function\n",
    "    ww_state['conversion_factor'] = conversion_factor_mapping[state]\n",
    "    ww_state['estimated_infections'] = ww_state['weighted_avg_conc'] * ww_state['conversion_factor']\n",
    "    \n",
    "    # Apply the rounding function to the relevant columns\n",
    "    ww_state['weighted_avg_conc'] = ww_state['weighted_avg_conc'].apply(round_to_two_significant_digits)\n",
    "\n",
    "    for index, row in ww_state.iterrows():\n",
    "        rows_list.append({'Country': 'United_States', 'Region': state, 'Date': row['Date'], 'Measure': 'inf', 'Value': row['estimated_infections']})\n",
    "        rows_list.append({'Country': 'United_States', 'Region': state, 'Date': row['Date'], 'Measure': 'wastewater', 'Value': row['weighted_avg_conc']})\n",
    "\n",
    "# Convert the combined DataFrame to JSON for use with ECharts\n",
    "combined_df = pd.concat([pd.DataFrame(rows_list)], ignore_index=True)\n",
    "\n",
    "combined_df.to_csv('US_states_min.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
